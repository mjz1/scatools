---
title: "scatools"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{scatools}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
)
```

We start by loading `scatools` and `ArchR`, as well as the filepath to an example `fragments.bed.gz` file containing fragments from 100 normal mammary cells. This bed file was generated using the `reformatFragmentFiles()` function from the `ArchR` package.

Note that all steps in this vignette work with a list of fragment files from multiple samples as well.
```{r setup}
library(scatools)
library(ArchR)
library(BSgenome.Hsapiens.UCSC.hg38)

addArchRThreads(8)
addArchRGenome("hg38")

fragment_file <- system.file("extdata", "fragments.bed.gz", package = "scatools")
names(fragment_file) <- "test_sample"

# Set up example output directories
arrow_dir = "./example/ArrowFiles"
bindepth_dir = "./example/binned_depth"
scatools_dir = "./example/scatools_analysis"

invisible(lapply(list(arrow_dir, bindepth_dir, scatools_dir), dir.create, showWarnings = FALSE, recursive = TRUE))
```


We first create an ArrowFile from the fragments file using the `ArchR` package. If you already have processed ArrowFiles you can skip to the `scatools` processing steps.
```{r}
knitr::opts_chunk$set(root.dir = arrow_dir)

setwd(arrow_dir)

ArrowFiles <- createArrowFiles(
  inputFiles = fragment_file,
  sampleNames = names(fragment_file),
  minTSS = 4, #Dont set this too high because you can always increase later
  minFrags = 1000,
  addTileMat = TRUE,
  addGeneScoreMat = TRUE,
  force = FALSE
)

# Calculate doublet scores
doubScores <- addDoubletScores(
  input = ArrowFiles,
  k = 10, #Refers to how many cells near a "pseudo-doublet" to count.
  knnMethod = "LSI", #Refers to the embedding to use for nearest neighbor search.
  LSIMethod = 1,
  force = FALSE
)

# Create an ArchR project file
proj <- ArchRProject(
  ArrowFiles = ArrowFiles,
  outputDirectory = "./",
  copyArrows = FALSE #This is recommended so that you maintain an unaltered copy for later usage.
)

proj <- filterDoublets(proj)
```

Now we process this data using `scatools`. Helper functions help us to create `GenomicRanges` bins, and compute GC content for downstream usage. Here we demonstrate using 10Mb bins.
```{r}
# Generate bins
bins <- get_tiled_bins(bs_genome = BSgenome.Hsapiens.UCSC.hg38, tilewidth = 1e7)

bin_name <- prettyMb(getmode(width(bins)))
message(bin_name)

head(bins)
```

Next we bin the atac fragments from the input ArrowFiles.
```{r}
# Bin the fragments
bin_atac_frags(ArrowFiles = getArrowFiles(proj), bins = bins, outdir = bindepth_dir, ncores = 8, overwrite = FALSE, return_mat = FALSE)
```


```{r}
samples <- file.path(bins_out, bin_name, sample_name)

for (i in seq_along(samples)) {
  samp_dir <- samples[i]
  samp_name <- sample_name[i]

  samp_outdir <- file.path(scatoolsdir, bin_name, samp_name)

  raw_out <- file.path(samp_outdir, "sce", "01_raw.sce")
  final_out <- file.path(samp_outdir, "sce", "02_hmm.sce")
  hmm_out <- file.path(samp_outdir, "hmm", "hmm_results.rda")

  logger::log_info("Processing sample {i} of {length(samples)}: {samp_name}")
  
  if (file.exists(final_out) & !overwrite) {
    logger::log_info("Final output exists! Skipping to next sample...")
    next
  }

  if (file.exists(raw_out) & !overwrite) {
    logger::log_info("Raw sce object found -- Loading...")
    sce <- get(load(raw_out))
  } else {
    sce <- load_atac_bins(
      samples = samp_dir,
      sample.names = samp_name,
      ArchR_Proj = proj,
      bins = bins,
      BPPARAM = BiocParallel::bpparam(),
      save_to = raw_out,
      verbose = verbose
    )
  }
  
  sce <- sce %>%
    add_ideal_mat(ncores = ncores, verbose = verbose) %>%
    add_gc_cor(method = "modal", verbose = verbose, ncores = ncores) %>%
    add_hmmcopy(verbose = verbose, ncores = ncores, save_raw_hmm = hmm_out)
  
  save_to(object = sce, save_to = final_out)
}

```

