#' Bin atac fragments
#'
#' Convenience wrapper to bin fragments of a given size and save them as `.mtx` files
#'
#' @inherit bin_frags
#'
#' @param ArrowFiles List or vector of ArrowFile paths
#' @param bin_name Name of the bins (e.g. `'10Mb'`, `'500Kb'`, `'chr_arm'`). If not provided is automatically detected based on binwidth.
#' @param overwrite Logical. Overwrite previously existing results (default = FALSE)
#' @param return_mat Logical. Return the binned depth matrix (default = FALSE)
#' @param ... Additional parameters passed to `bplapply`
#'
#' @return If `return_mat=TRUE`, returns a sparse binned depth matrix. Otherwise returns `NULL`
#'
#' @export
bin_atac_frags <- function(ArrowFiles, bins, outdir, bin_name = prettyMb(getmode(width(bins))), ncores = 1, bpparams = BiocParallel::MulticoreParam(workers = ncores, progressbar = TRUE), overwrite = FALSE, return_mat = FALSE, ...) {
  # TODO: optional outdir if we don't want to save

  stopifnot(class(bins) %in% "GRanges")

  # Compute fragments per bins and combine
  matlist <- lapply(X = seq_along(ArrowFiles), FUN = function(i) {
    sample_name <- names(ArrowFiles[i])
    ArrowFile <- ArrowFiles[i]
    sample_outdir <- file.path(outdir, bin_name, sample_name)

    # Only bin frags if not done already
    if (!file.exists(file.path(sample_outdir, "matrix.mtx.gz")) | overwrite) {
      logger::log_info("Computing fragments for ", sample_name)
      tmp <- bin_frags(ArrowFile = ArrowFile, bins = bins, outdir = sample_outdir, ncores = ncores, ...)
      return(tmp)
    } else {
      logger::log_info("Fragments files already found for ", sample_name)
    }
  })

  # Invisible return
  if (return_mat) {
    # or bind and then return
    res <- do.call("rbind", matlist)
    return(res)
  } else {
    return(invisible(NULL))
  }
}


#' Bin fragments from ArrowFile
#'
#' Parallel enabled depth counting of read fragments in given genomic bins from `ArchR` processed ArrowFiles
#'
#' @param ArrowFile ArrowFile
#' @param bins Bins GRanges object
#' @param outdir Optional: Directory to write the `.mtx`, `barcodes`, and `bins` files
#' @param ncores Number of cores to use
#' @param bpparams Options to `BPPARAM` to enable multithreading
#' @param verbose Logical. Message verbosity
#' @param ... Additional arguments passed to `bplapply`
#'
#' @return Binned depth sparse matrix
#' @export
bin_frags <- function(ArrowFile, bins, outdir = NULL, ncores = 1, bpparams = BiocParallel::MulticoreParam(workers = ncores, progressbar = TRUE), verbose = FALSE, ...) {
  requireNamespace("BiocParallel")

  stopifnot(class(bins) %in% "GRanges")

  if (verbose) {logger::log_info("Counting fragments in {length(bins)} bins using {ncores} cores")}

  result <- do.call("rbind", BiocParallel::bplapply(
    X = levels(BSgenome::seqnames(bins)),
    FUN = bin_frags_chr,
    bins = bins,
    ArrowFile = ArrowFile,
    BPPARAM = bpparams
  ))

  if (!is.null(outdir)) {
    cat("Writing to", outdir, "\n")
    dir.create(outdir, showWarnings = FALSE, recursive = TRUE)

    # Write output using dropletutils
    DropletUtils::write10xCounts(path = outdir, x = result, barcodes = colnames(result), gene.id = rownames(result), version = "3", overwrite = TRUE, gene.type = "Bin Counts")
  }

  return(result)
}


#' Bin scATAC fragments
#'
#' \code{bin_frags_chr} computes the fragments across bins in a single chromosome from an ArchR ArrowFile
#'
#' @param chr A single chromsome to compute depth information
#' @param bins A list of bins (can include all chromosomes)
#' @param ArrowFile Path to an ArrowFile generated by `ArchR`
#'
#' @return Sparse matrix of binned fragment counts
#' @export
#'
#' @examples
#' \dontrun{
#' dp_mat <- bin_frags_chr("chr1", get_chr_arm_bins("hg38"), ArrowFile)
#' }
bin_frags_chr <- function(chr, bins, ArrowFile) {
  if (!requireNamespace("ArchR", quietly = TRUE)) {
    stop("Package \"ArchR\" must be installed to use this function.")
  }

  stopifnot(length(chr) == 1)
  stopifnot(class(bins) %in% "GRanges")
  stopifnot(file.exists(ArrowFile))

  # Fix for parallel HDF5 access (if this function is passed to parallel loop)
  # We scope only to this function
  withr::local_envvar(c("HDF5_USE_FILE_LOCKING" = FALSE, "RHDF5_USE_FILE_LOCKING" = FALSE))

  # Export needed functions
  # .getFragsFromArrow <- utils::getFromNamespace(".getFragsFromArrow", "ArchR")
  # .availableCells <- utils::getFromNamespace(".availableCells", "ArchR")
  # h5closeAll <- utils::getFromNamespace("h5closeAll", "rhdf5")


  # Load ArchR package temporarily (if not loaded) to execute the following commands
  # This is required as ArchR has depends from rhdf5 and other packages that it does not properly reference using '::'
  # Side effect is that the ArchR namespace remains attached afterwards (ie all the packages it depends on)
  if (!"ArchR" %in% .packages()) {
    withr::local_package(package = "ArchR")
    ArchR::addArchRThreads(1)
  }

  # Export needed functions
  .getFragsFromArrow <- utils::getFromNamespace(".getFragsFromArrow", "ArchR")
  .availableCells <- utils::getFromNamespace(".availableCells", "ArchR")

  # Get cells
  cellNames <- .availableCells(ArrowFile)

  # Read in Fragments
  fragments <- .getFragsFromArrow(ArrowFile, chr = chr, out = "GRanges", cellNames = cellNames)


  # TODO: Remove fragments in blacklist regions?

  # Chromosome bins
  bins_chr <- bins[BSgenome::seqnames(bins) == chr]

  # Get overlapping indices
  # Note: Each fragment represents two transposition events
  # Therefore we count both the start and end site of each independently
  start_hits <- GenomicRanges::findOverlaps(
    subject = bins_chr,
    query = GRanges(
      seqnames = chr,
      IRanges::IRanges(
        start = GenomicRanges::start(fragments),
        end = GenomicRanges::start(fragments)
      )
    )
  )
  end_hits <- GenomicRanges::findOverlaps(
    subject = bins_chr,
    query = GenomicRanges::GRanges(
      seqnames = chr,
      IRanges::IRanges(
        start = GenomicRanges::end(fragments),
        end = GenomicRanges::end(fragments)
      )
    )
  )

  # Match Cells
  matchID <- S4Vectors::match(mcols(fragments)$RG, cellNames)

  # Create Sparse Matrix
  mat <- Matrix::sparseMatrix(
    i = c(to(start_hits), to(end_hits)),
    j = as.vector(c(matchID, matchID)),
    x = rep(1, 2 * length(fragments)),
    dims = c(length(bins_chr), length(cellNames))
  )

  # Name matrix
  colnames(mat) <- cellNames
  rownames(mat) <- paste(GenomicRanges::seqnames(bins_chr),
    GenomicRanges::start(bins_chr),
    GenomicRanges::end(bins_chr),
    sep = "_"
  )

  # Clean and return
  rm(fragments, matchID)
  gc()
  return(mat)
}


#' Get chromosome arm bins
#'
#' @param genome Genome version ('hg38', 'hg19')
#' @param calc_gc Logical: Whether or not to calculate GC content per bin
#' @param bs_genome BSgenome object. Must be passed if `calc_gc` is set to `TRUE`
#'
#' @return A GRanges object of chromosome arm bins
#' @export
#'
#' @examples
#' bins <- get_chr_arm_bins("hg38")
get_chr_arm_bins <- function(genome = "hg38", calc_gc = FALSE, bs_genome = NULL) {
  bins <- get_cytobands() %>%
    dplyr::group_by(CHROM, arm, genome) %>%
    dplyr::summarise(
      "start" = min(start),
      "end" = max(end)
    ) %>%
    dplyr::mutate("bin_id" = paste(CHROM, start, end, sep = "_")) %>%
    GenomicRanges::makeGRangesFromDataFrame(keep.extra.columns = T)
  bins$binwidth <- IRanges::width(bins)

  if (calc_gc) {
    if (is.null(bs_genome)) {
      stop("To calculate GC content you must pass a BSgenome object")
    }
    stopifnot(class(bs_genome) %in% "BSgenome")

    bins <- add_gc_freq(bins = bins, bs_genome = bs_genome)
  }
  bins <- sort(bins)

  return(bins)
}

#' Get tiled bins
#'
#' @param bs_genome A BSgenome object
#' @param tilewidth Bin size
#' @param select_chrs Vector of chromosomes to include
#'
#' @return A GRanges object of bins
#' @export
#'
#' @examples
#' \dontrun{
#' bins <- get_tiled_bins(BSgenome.Hsapiens.UCSC.hg38::BSgenome.Hsapiens.UCSC.hg38, tilewidth = 500000)
#' }
get_tiled_bins <- function(bs_genome, tilewidth = 500000, select_chrs = NULL) {
  stopifnot(class(bs_genome) %in% "BSgenome")

  if (is.null(select_chrs)) {
    select_chrs <- paste("chr", c(1:22, "X"), sep = "")
  }

  bins <- GenomicRanges::tileGenome(BSgenome::seqinfo(bs_genome)[select_chrs],
    tilewidth = tilewidth,
    cut.last.tile.in.chrom = TRUE
  )
  bins$binwidth <- IRanges::width(bins)

  bins$bin_id <- paste(seqnames(bins), start(bins), end(bins), sep = "_")

  bins <- add_gc_freq(bs_genome, bins)
  bins <- sort(bins)
  return(bins)
}


#' Get genome cytobands
#'
#' @param genome Genome version (hg38 or hg19)
#'
#' @return Dataframe of genome cytobands
#' @export
#'
#' @examples
#' hg38_cyto <- get_cytobands("hg38")
get_cytobands <- function(genome = "hg38") {
  cyto_url <- paste0("http://hgdownload.cse.ucsc.edu/goldenpath/", genome, "/database/cytoBand.txt.gz")
  cyto <- readr::read_delim(file = "http://hgdownload.cse.ucsc.edu/goldenpath/hg38/database/cytoBand.txt.gz", col_names = c("CHROM", "start", "end", "cytoband", "unsure"), show_col_types = FALSE) %>%
    dplyr::filter(!is.na(cytoband)) %>%
    dplyr::mutate(dplyr::across(where(is.character), as.factor),
      "start" = start + 1,
      "arm" = factor(substr(cytoband, 0, 1)),
      "genome" = genome
    )
  return(cyto)
}


#' Add GC frequency
#'
#' @param bs_genome BSGenome object
#' @param bins GRanges bins object
#'
#' @return GRanges bin object with GC and N frequency per bin
#' @export
#'
add_gc_freq <- function(bs_genome, bins) {
  stopifnot(class(bs_genome) %in% "BSgenome")
  logger::log_info("Computing GC content...")
  freqs <- BSgenome::alphabetFrequency(BSgenome::getSeq(bs_genome, bins))
  bins$gc <- (freqs[, "C"] + freqs[, "G"]) / rowSums(freqs)

  # Add N frequency
  bins$n_freq <- (freqs[, "N"]) / rowSums(freqs)

  return(bins)
}


#' Get ideal bin matrix
#'
#' Given a matrix of bin counts, bin gc and N frequency, and filtering parameters, return a boolean matrix flagging ideal bins
#'
#'
#' @param mat,sce A count matrix or SCE object depending on the function
#' @param ncores number of cores for parallel evaluation (requires [pbmcapply] package)
#'
#' @inherit is_ideal_bin
#' @export
#'
get_ideal_mat <- function(mat, gc, n_freq, map, min_reads = 1, max_N_freq = 0.05, reads_outlier = 0.01, gc_outlier = 0.001, min_map = 0.9, ncores = 1, verbose = FALSE) {
  if (verbose) {logger::log_info("Computing ideal bins in {ncol(mat)} cells using {ncores} threads")}
  if (requireNamespace("pbmcapply")) {
    res <- do.call(
      "cbind",
      pbmcapply::pbmclapply(X = seq_len(ncol(mat)), mc.cores = ncores, FUN = function(i) {
        is_ideal_bin(
          counts = mat[, i],
          gc = gc,
          n_freq = n_freq,
          map = map,
          min_reads = min_reads,
          max_N_freq = max_N_freq,
          reads_outlier = reads_outlier,
          gc_outlier = gc_outlier,
          min_map = min_map
        )
      })
    )
  } else {
    logger::log_warn("No parallel backend detected. Ideal mat computation may be slow", call. = FALSE)
    res <- do.call(
      "cbind",
      lapply(X = seq_len(ncol(mat)), FUN = function(i) {
        is_ideal_bin(
          counts = mat[, i],
          gc = gc,
          n_freq = n_freq,
          map = map,
          min_reads = min_reads,
          max_N_freq = max_N_freq,
          reads_outlier = reads_outlier,
          gc_outlier = gc_outlier,
          min_map = min_map
        )
      })
    )
  }

  if (verbose) {logger::log_success("Computing ideal bins completed!")}

  # Sort of silly but works for now to return both matrices
  ideal_mat <- res[, grep("ideal", colnames(res))]
  colnames(ideal_mat) <- colnames(mat)
  rownames(ideal_mat) <- rownames(mat)
  valid_mat <- res[, grep("valid", colnames(res))]
  colnames(valid_mat) <- colnames(mat)
  rownames(valid_mat) <- rownames(mat)

  return(list(ideal = as.matrix(ideal_mat), valid = as.matrix(valid_mat)))
}


#' Length normalize counts
#'
#' By default this procedure will only impact counts in the bins that are variable length (for example tail ends of chromosomes).
#'
#' @param sce SCE object
#' @param assay_name Name of assay to normalize
#' @param binwidth Bin width
#' @param by_factor Multiplication factor for counts
#' @param verbose Print verbose (TRUE/FALSE)
#'
#' @return An sce object with counts length normalized in `assay(sce, 'counts_permb')`
#' @export
#'
length_normalize <- function(sce, assay_name = "counts", assay_to = "counts_lenNorm", binwidth, by_factor = getmode(binwidth), verbose = FALSE) {
  if (verbose) {
    logger::log_info("Performing bin-length normalization. Storing as assay(sce, '", assay_to, "')")
  }

  # Bin length normalize upfront
  # Mainly necessary for our chr arm analysis where bins are variable in size
  # This is effectively an reads per Megabase (RPBMb) calculation. For reminder: https://www.rna-seqblog.com/rpkm-fpkm-and-tpm-clearly-explained/

  assay(sce, assay_to) <- assay(sce, assay_name) / binwidth * by_factor

  return(sce)
}



#' @rdname get_ideal_mat
#'
add_ideal_mat <- function(sce, assay_name = "counts", gc = rowData(sce)$gc, n_freq = rowData(sce)$n_freq, map = rowData(sce)$map, min_reads = 1, max_N_freq = 0.05, reads_outlier = 0.01, gc_outlier = 0.001, min_map = 0.9, ncores = 1, verbose = FALSE) {
  id_val_mats <- get_ideal_mat(
    mat = assay(sce, assay_name),
    gc = gc,
    n_freq = n_freq,
    map = map,
    min_reads = min_reads,
    max_N_freq = max_N_freq,
    reads_outlier = reads_outlier,
    gc_outlier = gc_outlier,
    min_map = min_map,
    ncores = ncores,
    verbose = verbose
  )

  assay(sce, "ideal_bins") <- id_val_mats$ideal
  assay(sce, "valid_bins") <- id_val_mats$valid

  return(sce)
}


#' Flag ideal bins
#'
#' `is_ideal_bin` will apply a set of bin-wise filters, based on high count outliers, high or low gc outliers, minimum read counts, minimum mappability, or maximum allowable frequency of N bases per bin.
#'
#' @param counts Vector of bin counts for single cell
#' @param gc Vector of gc content
#' @param n_freq Vector of bin N frequency (proportion of N bases in a bin)
#' @param map Vector of bin mappability
#' @param min_reads Minimum number of reads to consider a bin
#' @param max_N_freq Maximum allowable frequency of N bases to consider a bin. Range (0, 1)
#' @param reads_outlier Flag bins with reads in the top quantile given by this value. Range (0, 1)
#' @param gc_outlier Flag bins with GC content in the top and bottom quantule given by this value. Range (0, 1)
#' @param min_map Minimum allowable mappability score for a bin. Range (0, 1)
#'
#' @return A dataframe of two columns meet the `valid` or `ideal` criteria
#' @export
#'
is_ideal_bin <- function(counts, gc, n_freq, map = NULL, min_reads = 0, max_N_freq = 0.05, reads_outlier = 0.01, gc_outlier = 0.001, min_map = 0.9) {


  counts <- as.vector(counts)
  gc <- as.vector(gc)
  n_freq <- as.vector(n_freq)

  # Currently we use a placeholder for mappability. It doesn't do antyhing in the function yet
  if (is.null(map)) {
    map <- as.vector(rep(1, length(counts)))
  } else {
    map <- as.vector(map)
  }

  # Check lengths are equal and not zero
  if (var(unlist(lapply(list(counts, gc, n_freq, map), length))) != 0) {
    stop("counts, gc, n_freq, and map must be the same length. Check input data!")
  }

  if (length(counts) == 0){
    stop("No data...")
  }

  # First identify valid bins
  valid <- is_valid_bin(counts = counts, n_freq = n_freq, min_reads = min_reads, max_N_freq = max_N_freq)

  # Subset for the valid counts/bins in computing quantiles
  # Remove high read outliers
  read_range <- quantile(counts[valid], probs = c(0, 1 - reads_outlier))

  # Remove outlier GC bins on both sides
  gc_range <- quantile(gc[valid], probs = c(gc_outlier, 1 - gc_outlier))

  # Is ideal if meeting all the following criteria
  ideal <- valid &
    (map > min_map) &
    (counts < read_range[2]) &
    (counts >= read_range[1]) &
    (gc < gc_range[2]) &
    (gc > gc_range[1])

  return(data.frame(ideal = ideal, valid = valid))
}


is_valid_bin <- function(counts, n_freq, min_reads = 0, max_N_freq = 0.05) {
  # Only valid if having both min reads and min n_freq
  counts > min_reads & n_freq <= max_N_freq
}
